# 具身智能通用家庭机器人数据闭环系统 - 开发架构设计文档

**版本**: V1.0  
**日期**: 2026年1月7日  
**文档类型**: 开发架构设计  
**适用对象**: 后端开发工程师、嵌入式工程师、算法工程师、前端工程师、DevOps工程师

---

## 目录

- [第一章：文档概述与需求分析](#第一章文档概述与需求分析)
- [第二章：系统总体架构设计](#第二章系统总体架构设计)
- [第三章：采集层模块设计](#第三章采集层模块设计)
- [第四章：传输层模块设计](#第四章传输层模块设计)
- [第五章：处理层模块设计](#第五章处理层模块设计)
- [第六章：存储层模块设计](#第六章存储层模块设计)
- [第七章：管理层模块设计](#第七章管理层模块设计)
- [第八章：核心接口与数据契约](#第八章核心接口与数据契约)
- [第九章：代码工程结构](#第九章代码工程结构)
- [第十章：技术选型与开发规范](#第十章技术选型与开发规范)
- [附录](#附录)

---

## 第一章：文档概述与需求分析

### 1.1 文档目的

本文档从**开发编码人员**视角出发，对具身智能通用家庭机器人数据闭环系统进行功能拆分和模块化架构设计，为开发团队提供：

- **模块划分指南**：明确各功能模块边界、职责与依赖关系
- **接口规范定义**：统一模块间通信协议、数据格式与API设计
- **代码组织结构**：标准化项目目录、包结构与命名规范
- **技术选型参考**：指导开发语言、框架、中间件与工具选择
- **开发规范约定**：确保代码质量、团队协作效率与系统可维护性

### 1.2 核心需求提炼

基于参考文档分析，系统需解决具身智能领域的**"数据鸿沟"**问题，核心需求如下：

| 需求类别 | 具体要求 | 优先级 | 技术挑战 |
|----------|----------|--------|----------|
| **多模态同步采集** | RGB-D视频(30fps)、关节力矩(100Hz)、触觉(200Hz)、音频(16kHz) | P0 | 时序同步误差<10ms |
| **隐私原生安全** | 边缘侧实时脱敏，敏感数据不出域 | P0 | 处理延迟<40ms |
| **三模式采集** | 遥操作、自主采集、仿真采集融合 | P0 | 数据格式统一 |
| **质量门禁** | 自动质量分级(A/B/C/D)，训练友好输出 | P1 | VLM自动标注 |
| **数据闭环** | 采集→训练→部署→回流→优化循环 | P1 | 影子模式验证 |
| **可扩展性** | 单机到百机集群无缝扩展 | P2 | 分布式架构 |

### 1.3 关键技术约束

| 约束类型 | 约束内容 | 设计影响 |
|----------|----------|----------|
| **实时性** | 端到端延迟<50ms | 边缘计算优先 |
| **算力受限** | 边缘设备(Jetson Orin)算力有限 | 轻量模型+动态调度 |
| **网络带宽** | 家庭WiFi上行50-200Mbps | 自适应压缩+增量传输 |
| **安全底线** | 采集进程不阻塞安全控制回路 | 进程隔离+优先级调度 |
| **成本控制** | 单采集站<5万元 | 硬件选型优化 |

### 1.4 术语定义

| 术语 | 英文 | 说明 |
|------|------|------|
| **Episode** | Episode | 一次完整任务执行的数据记录单元 |
| **Chunk** | Chunk | Episode的子窗口，训练消费的最小单元(T=16/32/64 steps) |
| **VLA** | Vision-Language-Action | 视觉-语言-动作端到端模型 |
| **PTP** | Precision Time Protocol | IEEE 1588精确时间协议，实现μs级同步 |
| **QoS** | Quality of Service | ROS 2服务质量策略 |
| **DDS** | Data Distribution Service | ROS 2底层通信中间件 |
| **CoT** | Chain of Thought | 思维链，推理过程的逐步分解 |
| **Sim2Real** | Simulation-to-Reality | 仿真数据迁移到真实世界 |

---

## 第二章：系统总体架构设计

### 2.1 五层分层架构

系统采用**"采集-传输-处理-存储-管理"五层架构**，各层职责明确、接口解耦。

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         管理层 (Management Layer)                        │
│    ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌──────────┐  │
│    │  TaskManager │  │ DeviceMonitor│  │ AccessControl│  │ OpsAssist │  │
│    │   任务管理    │  │   设备监控    │  │   权限控制    │  │  运维助手  │  │
│    └──────────────┘  └──────────────┘  └──────────────┘  └──────────┘  │
├─────────────────────────────────────────────────────────────────────────┤
│                         存储层 (Storage Layer)                           │
│    ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌──────────┐  │
│    │  EdgeCache   │  │  CloudStore  │  │ VersionControl│ │FormatConv │  │
│    │   边缘缓存    │  │   云端存储    │  │   版本管理    │  │  格式转换  │  │
│    └──────────────┘  └──────────────┘  └──────────────┘  └──────────┘  │
├─────────────────────────────────────────────────────────────────────────┤
│                         处理层 (Processing Layer)                        │
│    ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐         │
│    │TimeSync │ │Privacy  │ │Quality  │ │AutoLabel│ │Semantic │         │
│    │时间同步  │ │隐私脱敏  │ │质量门禁  │ │自动标注  │ │语义去重  │         │
│    └─────────┘ └─────────┘ └─────────┘ └─────────┘ └─────────┘         │
├─────────────────────────────────────────────────────────────────────────┤
│                         传输层 (Transmission Layer)                      │
│    ┌──────────────┐  ┌──────────────┐  ┌──────────────┐                 │
│    │   ROSBus     │  │ CloudTransport│ │SecureChannel │                 │
│    │  ROS消息总线  │  │   云端传输    │  │   加密通道    │                 │
│    └──────────────┘  └──────────────┘  └──────────────┘                 │
├─────────────────────────────────────────────────────────────────────────┤
│                         采集层 (Acquisition Layer)                       │
│    ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌──────────┐  │
│    │   Teleop     │  │  Autonomous  │  │  Simulation  │  │SensorDriver│ │
│    │  遥操作采集   │  │   自主采集    │  │   仿真采集    │  │ 传感器驱动 │  │
│    └──────────────┘  └──────────────┘  └──────────────┘  └──────────┘  │
└─────────────────────────────────────────────────────────────────────────┘
```

### 2.2 层级职责分配

| 层级 | 核心职责 | 部署位置 | 关键技术栈 |
|------|---------|---------|-----------|
| **采集层** | 多模态数据获取：遥操作/自主/仿真 | 边缘端(机器人) | ROS 2 Humble, 传感器SDK |
| **传输层** | 数据同步与传输：本地+云端 | 边缘端+云端 | DDS, MQTT over TLS |
| **处理层** | 预处理与质量控制：清洗/同步/脱敏/标注 | 边缘端(实时)+云端(批量) | OpenCV, TensorRT, VLM |
| **存储层** | 分层存储管理：边缘缓存+云端+冷归档 | 边缘端SSD+云端OSS | MCAP, WebDataset, Parquet |
| **管理层** | 任务编排与监控：配置/监控/权限 | 云端+本地Web | FastAPI, React, Grafana |

### 2.3 边缘-云协同架构

```
┌────────────────────────────────────────────────────────────────────────┐
│                          云端 (Cloud)                                   │
│  ┌────────────────────────────────────────────────────────────────┐   │
│  │  数据湖(OSS/S3)   GPU集群(模型训练)   VLM标注服务   运维监控中心   │   │
│  │  版本控制系统      数据管理平台        模型仓库      告警服务       │   │
│  └────────────────────────────────────────────────────────────────┘   │
│                         ↑ MQTT/TLS 加密上传                            │
│                         ↓ 模型/配置/策略下发                            │
├────────────────────────────────────────────────────────────────────────┤
│                          边缘 (Edge) - Jetson Orin                      │
│  ┌────────────────────────────────────────────────────────────────┐   │
│  │  ┌───────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐      │   │
│  │  │ 实时预处理 │ │ 隐私脱敏   │ │ 本地缓存   │ │ 智能压缩   │      │   │
│  │  │           │ │  (<40ms)  │ │ (2TB SSD) │ │  (H.265)  │      │   │
│  │  └───────────┘ └───────────┘ └───────────┘ └───────────┘      │   │
│  │  ┌───────────┐ ┌───────────┐ ┌───────────┐                    │   │
│  │  │ PTP时间同步│ │ 质量监控   │ │ 资源调度   │                    │   │
│  │  └───────────┘ └───────────┘ └───────────┘                    │   │
│  └────────────────────────────────────────────────────────────────┘   │
│                         ↑ USB 3.0 / Ethernet / CAN                     │
│                         ↓ 控制指令                                      │
├────────────────────────────────────────────────────────────────────────┤
│                          采集端 (Sensors)                               │
│  ┌────────────────────────────────────────────────────────────────┐   │
│  │  RGB-D相机×4    触觉传感器×2    麦克风阵列    IMU+关节编码器       │   │
│  │  六维力传感器    遥操作设备(VR/动捕)                               │   │
│  └────────────────────────────────────────────────────────────────┘   │
└────────────────────────────────────────────────────────────────────────┘
```

### 2.4 数据流向图

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         完整数据流                                       │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  [传感器] ──→ [ROS节点] ──→ [Sync对齐] ──→ [隐私脱敏] ──→ [质量检测]    │
│      │                                                │                 │
│      ↓                                                ↓                 │
│  原始数据                                        ┌────────────┐         │
│  (高频/多源)                                     │ 边缘缓存    │         │
│                                                 │ (2TB SSD)  │         │
│                                                 └─────┬──────┘         │
│                                                       │                 │
│                  ┌────────────────────────────────────┼───────────┐     │
│                  │          网络传输 (自适应策略)       │           │     │
│                  │   全量模式 / 抽样模式 / 仅元数据模式 │           │     │
│                  └────────────────────────────────────┼───────────┘     │
│                                                       ↓                 │
│                                                 ┌────────────┐         │
│                                                 │ 云端存储    │         │
│                                                 └─────┬──────┘         │
│                                                       ↓                 │
│                   [VLM标注] ──→ [语义去重] ──→ [格式转换] ──→ [训练集]   │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### 2.5 系统组件依赖关系

```
采集层组件                传输层组件              处理层组件
┌─────────────┐          ┌─────────────┐        ┌─────────────┐
│SensorDriver │──publish→│  ROSBus     │──sub──→│  TimeSync   │
│TeleopModule │──publish→│  (DDS)      │        │  (对齐)     │
│AutoCollector│──publish→│             │        └──────┬──────┘
│SimCollector │──publish→└─────────────┘               │
└─────────────┘                                        ↓
                                               ┌─────────────┐
                                               │PrivacyFilter│
                                               │  (脱敏)     │
                                               └──────┬──────┘
                                                      │
存储层组件                管理层组件                   ↓
┌─────────────┐          ┌─────────────┐       ┌─────────────┐
│ EdgeCache   │←─write───│TaskManager  │       │QualityGate  │
│ CloudStore  │←─upload──│DeviceMonitor│       │  (质量检测)  │
│FormatConvert│←─convert─│AccessControl│       └──────┬──────┘
└─────────────┘          └─────────────┘              │
      ↑                                               │
      └───────────────────────────────────────────────┘
```

---

## 第三章：采集层模块设计

采集层是数据入口，负责稳定、高保真地获取原始数据流。采用**"三模式融合"**设计。

### 3.1 传感器驱动模块 (sensor_driver)

#### 3.1.1 模块职责

管理所有传感器的初始化、数据采集、状态监控，提供统一的数据输出接口。

#### 3.1.2 子模块划分

| 子模块 | 职责 | 输出Topic | 频率 | 关键类 |
|--------|------|-----------|------|--------|
| `camera_driver` | RGB-D相机采集 | `/sensor/camera/<id>/rgb`<br>`/sensor/camera/<id>/depth` | 30Hz | `RealSenseDriver` |
| `tactile_driver` | 触觉传感器采集 | `/sensor/tactile/<id>/force` | 200Hz | `GelSightDriver` |
| `audio_driver` | 麦克风阵列采集 | `/sensor/audio/raw` | 16kHz | `AudioArrayDriver` |
| `imu_driver` | IMU数据采集 | `/sensor/imu/data` | 1000Hz | `IMUDriver` |
| `force_torque_driver` | 六维力传感器 | `/sensor/ft/wrench` | 100Hz | `ForceTorqueDriver` |
| `joint_state_driver` | 关节编码器采集 | `/robot/joint_states` | 1000Hz | `JointStateDriver` |

#### 3.1.3 核心接口设计

```python
# sensor_driver/interfaces/base_sensor.py
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Optional, Dict, Any
import numpy as np

@dataclass
class SensorFrame:
    """传感器帧数据结构"""
    data: np.ndarray
    timestamp_ns: int          # 纳秒级时间戳
    frame_id: str              # 坐标系ID
    sequence: int              # 帧序号
    metadata: Dict[str, Any]   # 扩展元数据

class SensorHealth:
    UNKNOWN = 0
    HEALTHY = 1
    DEGRADED = 2
    FAULT = 3

class BaseSensor(ABC):
    """传感器基类 - 所有传感器驱动必须继承"""
    
    def __init__(self, sensor_id: str, config: Dict[str, Any]):
        self.sensor_id = sensor_id
        self.config = config
        self._health_status = SensorHealth.UNKNOWN
    
    @abstractmethod
    def initialize(self) -> bool:
        """初始化传感器硬件连接"""
        pass
    
    @abstractmethod
    def get_frame(self) -> Optional[SensorFrame]:
        """获取最新帧数据"""
        pass
    
    @abstractmethod
    def shutdown(self) -> None:
        """安全关闭传感器"""
        pass
    
    def get_health(self) -> int:
        return self._health_status
```

#### 3.1.4 传感器配置示例

```yaml
# config/sensors.yaml
sensors:
  cameras:
    - id: "head_left"
      type: "realsense_d455"
      serial: "xxxx"
      resolution: [1920, 1080]
      fps: 30
      enable_depth: true
      ptp_enabled: true
      
  tactile:
    - id: "left_finger"
      type: "gelsight_mini"
      port: "/dev/ttyUSB0"
      sampling_rate: 200
```

### 3.2 遥操作采集模块 (teleop_acquisition)

#### 3.2.1 模块职责

管理遥操作设备接入、主从动作映射、数据录制会话。

#### 3.2.2 子模块划分

| 子模块 | 职责 | 关键接口 |
|--------|------|----------|
| `master_device` | 主端设备驱动(VR/动捕) | `/teleop/master/pose` |
| `slave_controller` | 从端机器人控制 | `/teleop/slave/cmd` |
| `motion_mapper` | 主从动作映射 | 内部服务 |
| `recording_manager` | 录制会话管理 | `/teleop/recording/status` |

#### 3.2.3 动作映射器核心实现

```python
# teleop_acquisition/motion_mapper.py
class MotionMapper:
    """主从动作映射器"""
    
    def __init__(self, config: MapperConfig):
        self.config = config
        self._workspace_limits = config.safety_limits
    
    def map_pose(self, master_pose: Pose) -> Pose:
        """将主端位姿映射到从端目标位姿"""
        slave_position = master_pose.position * self.config.position_scale + self.config.arm_offset
        slave_position = self._apply_safety_limits(slave_position)
        return Pose(position=slave_position, orientation=master_pose.orientation)
    
    def map_gripper(self, master_gripper: float) -> float:
        """映射夹爪开合度 [0,1]"""
        return np.clip(master_gripper * self.config.gripper_scale, 0.0, 1.0)
```

### 3.3 自主采集模块 (autonomous_acquisition)

#### 3.3.1 智能触发策略

| 触发类型 | 触发条件 | 优先级 |
|----------|----------|--------|
| **安全触发** | 碰撞/急停/卡死 | 0.9 |
| **人类干预** | 语音打断/手动接管 | 0.95 |
| **失败触发** | 任务超时/失败 | 0.85 |
| **不确定性** | 模型熵值高 | 0.8 |
| **新颖性** | 与历史向量库差异大 | 0.75 |

#### 3.3.2 触发管理器

```python
# autonomous_acquisition/trigger_manager.py
class TriggerManager:
    """智能数据触发管理器"""
    
    def should_record(self, state: RobotState) -> Tuple[bool, str, float]:
        # 安全事件 - 最高优先级
        if state.near_collision or state.emergency_stop:
            return True, "SAFETY_EVENT", 0.9
        # 人类干预
        if state.human_takeover:
            return True, "HUMAN_TAKEOVER", 0.95
        # 高不确定性
        if state.model_uncertainty > self.threshold:
            return True, "HIGH_UNCERTAINTY", 0.8
        # 新颖场景
        if state.novelty_score > 0.7:
            return True, "NOVEL_SCENE", 0.75
        return False, "", 0.0
```

### 3.4 仿真采集模块 (simulation_acquisition)

#### 3.4.1 域随机化配置

```python
@dataclass
class DomainRandomizationConfig:
    # 视觉随机化
    lighting_intensity: Tuple[float, float] = (0.2, 1.5)
    texture_randomize: bool = True
    # 物理随机化
    friction: Tuple[float, float] = (0.3, 1.2)
    mass_scale: Tuple[float, float] = (0.8, 1.2)
    # 几何随机化
    object_position_noise: float = 0.05  # 5cm
```

#### 3.4.2 仿真数据标记

```json
{
    "episode_id": "sim_ep_001",
    "data_source": "sim",
    "sim_fidelity_score": 0.75,
    "training_weight": 0.3
}
```

---

## 第四章：传输层模块设计

传输层负责数据的同步与传输，采用**"边缘本地传输+云端远程传输"**混合架构。

### 4.1 ROS消息总线模块 (ros_bus)

#### 4.1.1 模块职责

管理ROS 2节点间通信、消息路由、QoS配置。

#### 4.1.2 QoS配置策略

```python
# ros_bus/qos_profiles.py
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy, DurabilityPolicy

# 传感器数据：高频、允许丢帧
SENSOR_QOS = QoSProfile(
    reliability=ReliabilityPolicy.BEST_EFFORT,
    history=HistoryPolicy.KEEP_LAST,
    depth=10,
    durability=DurabilityPolicy.VOLATILE
)

# 控制指令：可靠传输
CONTROL_QOS = QoSProfile(
    reliability=ReliabilityPolicy.RELIABLE,
    history=HistoryPolicy.KEEP_LAST,
    depth=10,
    durability=DurabilityPolicy.TRANSIENT_LOCAL
)

# 状态数据：持久化
STATUS_QOS = QoSProfile(
    reliability=ReliabilityPolicy.RELIABLE,
    history=HistoryPolicy.KEEP_LAST,
    depth=1,
    durability=DurabilityPolicy.TRANSIENT_LOCAL
)
```

#### 4.1.3 Topic命名规范

```
/<namespace>/<module>/<data_type>

示例：
/data_collection/camera/head_left/rgb
/data_collection/tactile/left_finger/force
/data_collection/robot/joint_states
/data_collection/teleop/master/pose
```

### 4.2 时间同步模块 (time_sync)

#### 4.2.1 同步等级分层

| 等级 | 精度要求 | 适用模态 | 实现方式 |
|------|---------|---------|----------|
| L0_STRONG | <1ms | 控制/关节/力触觉 | 硬件PTP |
| L1_MEDIUM | <10ms | RGB ↔ 关节 | 软件同步器 |
| L2_WEAK | <100ms | 音频/环境 | 时间戳匹配 |

#### 4.2.2 多模态对齐器

```python
# time_sync/multimodal_aligner.py
import message_filters
from rclpy.node import Node

class MultimodalAligner(Node):
    """多模态数据对齐器"""
    
    def __init__(self):
        super().__init__('multimodal_aligner')
        
        # 订阅各模态数据
        self.rgb_sub = message_filters.Subscriber(self, Image, '/camera/rgb')
        self.depth_sub = message_filters.Subscriber(self, Image, '/camera/depth')
        self.joint_sub = message_filters.Subscriber(self, JointState, '/robot/joint_states')
        
        # 近似时间同步器 (允许最大50ms误差)
        self.sync = message_filters.ApproximateTimeSynchronizer(
            [self.rgb_sub, self.depth_sub, self.joint_sub],
            queue_size=10,
            slop=0.05
        )
        self.sync.registerCallback(self.aligned_callback)
        
        # 发布对齐后的数据
        self.aligned_pub = self.create_publisher(AlignedData, '/synced_data', 10)
    
    def aligned_callback(self, rgb_msg, depth_msg, joint_msg):
        """处理对齐后的多模态数据"""
        aligned = AlignedData()
        aligned.header.stamp = self.get_clock().now().to_msg()
        aligned.rgb = rgb_msg
        aligned.depth = depth_msg
        aligned.joint_states = joint_msg
        
        # 计算同步误差
        sync_error = self._compute_sync_error(rgb_msg, joint_msg)
        aligned.sync_error_ms = sync_error
        
        self.aligned_pub.publish(aligned)
```

#### 4.2.3 PTP硬件同步配置

```bash
# 启用PTP硬件同步
sudo systemctl enable ptp4l
sudo systemctl start ptp4l

# PTP配置文件 /etc/linuxptp/ptp4l.conf
[global]
twoStepFlag             1
priority1               128
priority2               128
domainNumber            0
clockAccuracy           0xFE
```

### 4.3 云端传输模块 (cloud_transport)

#### 4.3.1 自适应上传策略

| 网络状态 | 带宽阈值 | 策略 | 上传内容 |
|---------|---------|------|---------|
| 优质 | >10Mbps | full | 原始RGB-D+全量数据 |
| 一般 | 2-10Mbps | sampled | 关键帧(1fps)+状态数据 |
| 差 | <2Mbps | metadata | 任务摘要+关键事件 |

#### 4.3.2 上传服务实现

```python
# cloud_transport/uploader.py
import asyncio
from dataclasses import dataclass
from enum import Enum

class UploadStrategy(Enum):
    FULL = "full"
    SAMPLED = "sampled"
    METADATA_ONLY = "metadata"

@dataclass
class NetworkStatus:
    bandwidth_mbps: float
    latency_ms: float
    packet_loss: float

class AdaptiveUploader:
    """自适应上传服务"""
    
    def __init__(self, config: dict):
        self.config = config
        self.mqtt_client = self._init_mqtt_client()
        self.upload_queue = asyncio.PriorityQueue()
    
    def get_strategy(self, network: NetworkStatus) -> UploadStrategy:
        """根据网络状态选择上传策略"""
        if network.bandwidth_mbps > 10:
            return UploadStrategy.FULL
        elif network.bandwidth_mbps > 2:
            return UploadStrategy.SAMPLED
        else:
            return UploadStrategy.METADATA_ONLY
    
    async def upload_episode(self, episode_path: str, priority: float):
        """将Episode加入上传队列"""
        await self.upload_queue.put((-priority, episode_path))
    
    async def upload_loop(self):
        """上传主循环"""
        while True:
            network = await self._check_network()
            strategy = self.get_strategy(network)
            
            priority, episode_path = await self.upload_queue.get()
            
            if strategy == UploadStrategy.FULL:
                await self._upload_full(episode_path)
            elif strategy == UploadStrategy.SAMPLED:
                await self._upload_sampled(episode_path)
            else:
                await self._upload_metadata(episode_path)
```

#### 4.3.3 断点续传机制

```python
# cloud_transport/resume_manager.py
class ResumeManager:
    """断点续传管理器"""
    
    def __init__(self, checkpoint_dir: str):
        self.checkpoint_dir = checkpoint_dir
    
    def save_checkpoint(self, upload_id: str, uploaded_bytes: int, total_bytes: int):
        """保存上传断点"""
        checkpoint = {
            "upload_id": upload_id,
            "uploaded_bytes": uploaded_bytes,
            "total_bytes": total_bytes,
            "timestamp": time.time()
        }
        checkpoint_path = f"{self.checkpoint_dir}/{upload_id}.json"
        with open(checkpoint_path, 'w') as f:
            json.dump(checkpoint, f)
    
    def resume_upload(self, upload_id: str) -> Optional[int]:
        """恢复上传，返回已上传字节数"""
        checkpoint_path = f"{self.checkpoint_dir}/{upload_id}.json"
        if os.path.exists(checkpoint_path):
            with open(checkpoint_path) as f:
                checkpoint = json.load(f)
            return checkpoint["uploaded_bytes"]
        return None
```

---

## 第五章：处理层模块设计

处理层负责数据的预处理与质量控制，分为边缘端实时处理和云端批量处理。

### 5.1 隐私脱敏模块 (privacy_filter)

#### 5.1.1 模块职责

实时检测并处理敏感信息，确保原始敏感数据不出边缘节点。

#### 5.1.2 脱敏处理流水线

| 处理步骤 | 目标 | 延迟要求 | 技术方案 |
|---------|------|---------|---------|
| 人脸检测 | 检测图像中人脸 | <20ms | YOLOv8-Nano |
| 人脸模糊 | 模糊处理 | <10ms | 高斯模糊 |
| 文字检测 | 敏感文字(身份证等) | <30ms | PaddleOCR |
| 语音脱敏 | 声纹匿名化 | <50ms | 频率变换 |

#### 5.1.3 隐私脱敏引擎

```python
# privacy_filter/privacy_engine.py
import cv2
import numpy as np
from ultralytics import YOLO

class PrivacyEngine:
    """边缘侧隐私脱敏引擎"""
    
    def __init__(self, config: dict):
        self.config = config
        self.face_detector = YOLO(config.get("face_model", "yolov8n-face.pt"))
        self.text_detector = self._load_ocr_model()
        self.sensitive_keywords = config.get("sensitive_keywords", 
            ["身份证", "银行卡", "密码", "车牌"])
    
    def process_image(self, image: np.ndarray) -> Tuple[np.ndarray, dict]:
        """
        处理图像，返回脱敏后的图像和元数据
        延迟要求: <40ms
        """
        metadata = {"anonymized_regions": []}
        
        # 1. 人脸检测与模糊
        faces = self.face_detector(image, verbose=False)
        for result in faces:
            for box in result.boxes.xyxy.cpu().numpy():
                x1, y1, x2, y2 = map(int, box)
                image = self._blur_region(image, (x1, y1, x2, y2))
                metadata["anonymized_regions"].append({
                    "type": "face", "bbox": [x1, y1, x2, y2]
                })
        
        # 2. 敏感文字检测与遮挡
        texts = self.text_detector.detect(image)
        for text_box in texts:
            if self._contains_sensitive(text_box.content):
                image = self._mask_region(image, text_box.bbox)
                metadata["anonymized_regions"].append({
                    "type": "text", "bbox": text_box.bbox
                })
        
        return image, metadata
    
    def _blur_region(self, image: np.ndarray, bbox: tuple) -> np.ndarray:
        """对区域应用高斯模糊"""
        x1, y1, x2, y2 = bbox
        roi = image[y1:y2, x1:x2]
        blurred = cv2.GaussianBlur(roi, (99, 99), 30)
        image[y1:y2, x1:x2] = blurred
        return image
    
    def _contains_sensitive(self, text: str) -> bool:
        """检查是否包含敏感关键词"""
        return any(kw in text for kw in self.sensitive_keywords)
```

### 5.2 质量门禁模块 (quality_gate)

#### 5.2.1 质量分级标准

| 等级 | 技术指标 | 语义指标 | 用途 |
|------|---------|---------|------|
| **A级** | 同步误差<5ms，无模糊 | 标注置信度>0.9 | 直接入训练集 |
| **B级** | 同步误差<10ms，轻微模糊 | 标注置信度0.7-0.9 | 人工复核后入库 |
| **C级** | 同步误差>10ms，严重模糊 | 标注置信度<0.7 | 仅归档不训练 |
| **D级** | 数据缺失 | 无有效标注 | 丢弃 |

#### 5.2.2 质量检测实现

```python
# quality_gate/quality_evaluator.py
from dataclasses import dataclass
from enum import Enum
import cv2
import numpy as np

class QualityGrade(Enum):
    A = "A"
    B = "B"
    C = "C"
    D = "D"

@dataclass
class QualityReport:
    grade: QualityGrade
    sync_error_ms: float
    image_sharpness: float
    data_completeness: float
    annotation_confidence: float
    issues: list

class QualityEvaluator:
    """数据质量评估器"""
    
    def __init__(self, config: dict):
        self.config = config
        self.sharpness_threshold = config.get("sharpness_threshold", 100)
        self.sync_threshold_ms = config.get("sync_threshold_ms", 10)
    
    def evaluate(self, episode_data: dict) -> QualityReport:
        """评估Episode数据质量"""
        issues = []
        
        # 1. 图像清晰度检测 (拉普拉斯方差)
        sharpness = self._compute_sharpness(episode_data.get("rgb"))
        if sharpness < self.sharpness_threshold:
            issues.append(f"image_blur: sharpness={sharpness:.1f}")
        
        # 2. 时间同步误差
        sync_error = self._compute_sync_error(episode_data)
        if sync_error > self.sync_threshold_ms:
            issues.append(f"sync_error: {sync_error:.1f}ms")
        
        # 3. 数据完整性
        completeness = self._check_completeness(episode_data)
        if completeness < 0.95:
            issues.append(f"incomplete: {completeness*100:.1f}%")
        
        # 4. 综合评级
        grade = self._compute_grade(sharpness, sync_error, completeness)
        
        return QualityReport(
            grade=grade,
            sync_error_ms=sync_error,
            image_sharpness=sharpness,
            data_completeness=completeness,
            annotation_confidence=0.0,  # 由标注模块填充
            issues=issues
        )
    
    def _compute_sharpness(self, image: np.ndarray) -> float:
        """计算图像清晰度 (拉普拉斯方差)"""
        if image is None:
            return 0.0
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        return cv2.Laplacian(gray, cv2.CV_64F).var()
    
    def _compute_grade(self, sharpness, sync_error, completeness) -> QualityGrade:
        """计算综合质量等级"""
        if completeness < 0.5:
            return QualityGrade.D
        if sync_error > 10 or sharpness < 50:
            return QualityGrade.C
        if sync_error > 5 or sharpness < 100:
            return QualityGrade.B
        return QualityGrade.A
```

### 5.3 自动标注模块 (auto_labeling)

#### 5.3.1 VLM标注流程

```
原始Episode
    → 关键帧提取 (变化检测)
    → VLM模型 (GPT-4V/Qwen-VL)
    → 语义描述生成
        ├─ 物体检测与分类
        ├─ 动作类别标签
        └─ 思维链CoT标注
    → 置信度评估
    → 低置信度转人工复核
```

#### 5.3.2 CoT思维链结构

```python
# auto_labeling/cot_generator.py
from dataclasses import dataclass
from typing import List
from enum import Enum

class CoTStepType(Enum):
    PERCEPTION = "perception"
    PLANNING = "planning"
    EXECUTION = "execution"
    VALIDATION = "validation"

@dataclass
class CoTStep:
    step: int
    type: CoTStepType
    content: str
    confidence: float

@dataclass
class ChainOfThought:
    steps: List[CoTStep]
    natural_language: str

class CoTGenerator:
    """思维链标注生成器"""
    
    def __init__(self, vlm_client):
        self.vlm = vlm_client
        self.prompt_template = self._load_prompt_template()
    
    async def generate_cot(self, keyframes: list, task_description: str) -> ChainOfThought:
        """为Episode生成思维链标注"""
        prompt = self.prompt_template.format(
            task=task_description,
            num_frames=len(keyframes)
        )
        
        response = await self.vlm.chat(
            messages=[{"role": "user", "content": prompt}],
            images=keyframes
        )
        
        cot = self._parse_cot_response(response)
        return cot
```

---

## 第六章：存储层模块设计

存储层负责数据的分层存储管理，确保训练友好输出。

### 6.1 边缘缓存模块 (edge_cache)

#### 6.1.1 缓存配置

```yaml
# config/edge_cache.yaml
edge_cache:
  storage_path: "/data/cache"
  capacity_gb: 2000
  retention_days: 7
  eviction_policy: "oldest_first"
  integrity_check_interval: "1h"
  compression:
    enabled: true
    algorithm: "lz4"
```

#### 6.1.2 缓存管理器

```python
# storage/edge_cache/cache_manager.py
import os
from pathlib import Path
from typing import Optional
import shutil

class EdgeCacheManager:
    """边缘缓存管理器"""
    
    def __init__(self, config: dict):
        self.storage_path = Path(config["storage_path"])
        self.capacity_bytes = config["capacity_gb"] * 1024**3
        self.retention_days = config["retention_days"]
    
    def write_episode(self, episode_id: str, data: bytes) -> str:
        """写入Episode数据"""
        episode_path = self.storage_path / f"{episode_id}.mcap"
        episode_path.write_bytes(data)
        
        # 检查容量，必要时清理
        self._check_and_evict()
        
        return str(episode_path)
    
    def get_episode(self, episode_id: str) -> Optional[bytes]:
        """读取Episode数据"""
        episode_path = self.storage_path / f"{episode_id}.mcap"
        if episode_path.exists():
            return episode_path.read_bytes()
        return None
    
    def _check_and_evict(self):
        """检查容量并执行清理"""
        current_usage = self._get_usage()
        if current_usage > self.capacity_bytes * 0.9:
            self._evict_oldest()
    
    def _evict_oldest(self):
        """清理最旧的数据"""
        files = sorted(self.storage_path.glob("*.mcap"), key=lambda f: f.stat().st_mtime)
        while self._get_usage() > self.capacity_bytes * 0.7 and files:
            oldest = files.pop(0)
            oldest.unlink()
```

### 6.2 云端存储模块 (cloud_storage)

#### 6.2.1 三层存储策略

| 层级 | 存储类型 | 保留期限 | 成本 | 访问时间 |
|------|---------|---------|------|---------|
| 热数据 | OSS标准 | 7天 | 高 | 即时 |
| 温数据 | OSS低频 | 30天 | 中 | <1秒 |
| 冷数据 | OSS归档 | 长期 | 低 | 3-5小时 |

#### 6.2.2 OSS存储客户端

```python
# storage/cloud_storage/oss_client.py
import oss2
from dataclasses import dataclass

@dataclass
class StorageConfig:
    endpoint: str
    access_key_id: str
    access_key_secret: str
    bucket_name: str

class OSSStorageClient:
    """阿里云OSS存储客户端"""
    
    def __init__(self, config: StorageConfig):
        auth = oss2.Auth(config.access_key_id, config.access_key_secret)
        self.bucket = oss2.Bucket(auth, config.endpoint, config.bucket_name)
    
    def upload_episode(self, episode_id: str, local_path: str, metadata: dict) -> str:
        """上传Episode到OSS"""
        object_key = f"episodes/raw/{episode_id}.mcap"
        
        headers = {
            'x-oss-meta-quality-grade': metadata.get('quality_grade', ''),
            'x-oss-meta-trigger-type': metadata.get('trigger_type', ''),
        }
        
        self.bucket.put_object_from_file(object_key, local_path, headers=headers)
        return object_key
    
    def set_lifecycle(self, object_key: str, storage_class: str):
        """设置存储类型"""
        self.bucket.copy_object(
            self.bucket.bucket_name, object_key, object_key,
            headers={'x-oss-storage-class': storage_class}
        )
```

### 6.3 格式转换模块 (format_converter)

#### 6.3.1 支持的格式转换

| 输入格式 | 输出格式 | 用途 |
|---------|---------|------|
| MCAP (ROS 2) | WebDataset | PyTorch流式训练 |
| MCAP | HDF5 | 离线分析 |
| MCAP | Parquet | 数据仓库查询 |

#### 6.3.2 WebDataset转换器

```python
# storage/format_converter/webdataset_converter.py
import webdataset as wds
from mcap_ros2.reader import read_ros2_messages

class WebDatasetConverter:
    """MCAP到WebDataset转换器"""
    
    def __init__(self, output_dir: str):
        self.output_dir = output_dir
    
    def convert_episode(self, mcap_path: str, episode_id: str) -> str:
        """将MCAP转换为WebDataset格式"""
        output_path = f"{self.output_dir}/{episode_id}.tar"
        
        with wds.TarWriter(output_path) as sink:
            messages = read_ros2_messages(mcap_path)
            
            for idx, msg_group in enumerate(self._group_by_timestamp(messages)):
                sample = {
                    "__key__": f"{episode_id}_{idx:06d}",
                    "rgb.jpg": self._encode_image(msg_group.get("rgb")),
                    "depth.png": self._encode_depth(msg_group.get("depth")),
                    "joint.json": self._encode_json(msg_group.get("joint_states")),
                    "action.json": self._encode_json(msg_group.get("action")),
                    "meta.json": {"timestamp": msg_group["timestamp"]}
                }
                sink.write(sample)
        
        return output_path
```

---

## 第七章：管理层模块设计

管理层提供任务编排、设备监控和权限控制功能。

### 7.1 任务管理模块 (task_manager)

#### 7.1.1 任务状态机

```
[待分配] ──→ [进行中] ──→ [已完成]
     │           │
     ↓           ↓
 [已取消] ←── [暂停中]
```

#### 7.1.2 任务管理API

```python
# management/task_manager/api.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional, List
from enum import Enum

app = FastAPI(title="Task Management API")

class TaskStatus(str, Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    PAUSED = "paused"
    COMPLETED = "completed"
    CANCELLED = "cancelled"

class TaskCreate(BaseModel):
    name: str
    task_type: str  # teleop, autonomous, simulation
    scene: str
    modalities: List[str]
    duration_minutes: int

class TaskResponse(BaseModel):
    task_id: str
    name: str
    status: TaskStatus
    created_at: str
    progress: float

@app.post("/api/v1/tasks", response_model=TaskResponse)
async def create_task(task: TaskCreate):
    """创建采集任务"""
    task_id = generate_task_id()
    # 创建任务逻辑
    return TaskResponse(
        task_id=task_id,
        name=task.name,
        status=TaskStatus.PENDING,
        created_at=datetime.now().isoformat(),
        progress=0.0
    )

@app.post("/api/v1/tasks/{task_id}/start")
async def start_task(task_id: str):
    """启动采集任务"""
    pass

@app.post("/api/v1/tasks/{task_id}/stop")
async def stop_task(task_id: str):
    """停止采集任务"""
    pass
```

### 7.2 设备监控模块 (device_monitor)

#### 7.2.1 监控指标

| 监控项 | 正常范围 | 告警阈值 | 采集频率 |
|-------|---------|---------|---------|
| 传感器帧率 | ≥25fps | <20fps | 5s |
| 设备温度 | <55°C | >60°C | 10s |
| CPU占用率 | <70% | >85% | 5s |
| 磁盘剩余 | >20% | <10% | 60s |
| 网络延迟 | <50ms | >100ms | 5s |

#### 7.2.2 监控服务

```python
# management/device_monitor/monitor_service.py
from dataclasses import dataclass
from typing import Dict, List
import asyncio

@dataclass
class DeviceMetrics:
    device_id: str
    cpu_percent: float
    memory_percent: float
    temperature: float
    disk_usage_percent: float
    sensor_fps: Dict[str, float]
    network_latency_ms: float

class DeviceMonitorService:
    """设备监控服务"""
    
    def __init__(self, config: dict):
        self.config = config
        self.alert_thresholds = config["alert_thresholds"]
        self.devices: Dict[str, DeviceMetrics] = {}
    
    async def collect_metrics(self, device_id: str) -> DeviceMetrics:
        """采集设备指标"""
        # 通过ROS服务或HTTP API采集
        metrics = await self._query_device_metrics(device_id)
        self.devices[device_id] = metrics
        
        # 检查告警
        await self._check_alerts(metrics)
        
        return metrics
    
    async def _check_alerts(self, metrics: DeviceMetrics):
        """检查并触发告警"""
        alerts = []
        
        if metrics.temperature > self.alert_thresholds["temperature"]:
            alerts.append(f"High temperature: {metrics.temperature}°C")
        
        if metrics.cpu_percent > self.alert_thresholds["cpu_percent"]:
            alerts.append(f"High CPU usage: {metrics.cpu_percent}%")
        
        for sensor_id, fps in metrics.sensor_fps.items():
            if fps < self.alert_thresholds["min_fps"]:
                alerts.append(f"Low FPS on {sensor_id}: {fps}")
        
        if alerts:
            await self._send_alerts(metrics.device_id, alerts)
```

### 7.3 权限控制模块 (access_control)

#### 7.3.1 角色权限矩阵

| 角色 | 采集 | 查看 | 导出 | 删除 | 配置 |
|------|------|------|------|------|------|
| admin | ✓ | ✓ | ✓ | ✓ | ✓ |
| operator | ✓ | ✓ | ✗ | ✗ | ✗ |
| analyst | ✗ | ✓ | ✓ | ✗ | ✗ |
| viewer | ✗ | ✓ | ✗ | ✗ | ✗ |

---

## 第八章：核心接口与数据契约

### 8.1 Episode数据Schema

```json
{
    "episode_id": "ep_20260107_001",
    "session_id": "session_kitchen_001",
    "timestamp": 1736236800.123,
    "data_source": "real",
    
    "scene_metadata": {
        "scene_id": "home_kitchen_01",
        "scene_type": "kitchen",
        "lighting_condition": "natural_daylight"
    },
    
    "task_metadata": {
        "task_id": "task_pick_cup",
        "task_description": "拿起桌上的水杯",
        "outcome": "success"
    },
    
    "observations": {
        "rgb": {"head_left": "path/to/rgb.png"},
        "depth": {"head_left": "path/to/depth.png"},
        "joint_states": {
            "positions": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],
            "velocities": [0.01, 0.02, 0.01, 0.0, 0.0, 0.0]
        }
    },
    
    "actions": {
        "canonical_action": {
            "ee_delta": [0.01, 0.02, 0.0, 0.0, 0.0, 0.01],
            "gripper_state": 0.8,
            "coordinate_frame": "base_link"
        }
    },
    
    "annotations": {
        "action_label": "grasp",
        "cot": [
            {"step": 1, "type": "perception", "content": "cup_on_table"},
            {"step": 2, "type": "planning", "content": "grasp_handle"},
            {"step": 3, "type": "execution", "content": "close_gripper"}
        ]
    },
    
    "quality_metadata": {
        "quality_grade": "A",
        "sync_error_ms": 5.2
    }
}
```

### 8.2 训练字段契约

| 字段类型 | 字段名 | 必需性 | 说明 |
|---------|-------|-------|------|
| **Hard-Required** | `episode_id` | 必需 | 唯一标识 |
| **Hard-Required** | `observations.joint_states` | 必需 | 机器人状态 |
| **Hard-Required** | `actions.canonical_action` | 必需 | 规范化动作 |
| **Hard-Required** | `timestamp` | 必需 | 时间戳 |
| **Soft-Required** | `observations.rgb` | 推荐 | 视觉输入 |
| **Optional** | `annotations.cot` | 可选 | 思维链标注 |
| **Never-Train** | `raw_action` | 禁止 | 原始设备动作 |

### 8.3 REST API规范

| 接口 | 方法 | 功能 |
|------|------|------|
| `/api/v1/tasks` | GET/POST | 任务列表/创建 |
| `/api/v1/tasks/{id}` | GET/PUT/DELETE | 任务详情/更新/删除 |
| `/api/v1/tasks/{id}/start` | POST | 启动采集 |
| `/api/v1/tasks/{id}/stop` | POST | 停止采集 |
| `/api/v1/devices` | GET | 设备列表 |
| `/api/v1/episodes` | GET | Episode列表 |
| `/api/v1/episodes/{id}` | GET | Episode详情 |

### 8.4 WebSocket接口

| 接口 | 功能 |
|------|------|
| `/ws/realtime/video` | 实时视频预览 |
| `/ws/realtime/status` | 系统状态推送 |
| `/ws/realtime/alerts` | 告警消息推送 |

---

## 第九章：代码工程结构

### 9.1 项目目录结构

```
data_collection_system/
├── README.md
├── pyproject.toml
├── setup.py
├── docker/
│   ├── Dockerfile.edge
│   └── Dockerfile.cloud
├── config/
│   ├── sensors.yaml
│   ├── system.yaml
│   └── privacy.yaml
├── launch/
│   ├── edge_system.launch.py
│   └── teleop_mode.launch.py
├── src/
│   ├── acquisition/           # 采集层
│   │   ├── __init__.py
│   │   ├── sensor_driver/
│   │   ├── teleop/
│   │   ├── autonomous/
│   │   └── simulation/
│   ├── transmission/          # 传输层
│   │   ├── __init__.py
│   │   ├── ros_bus/
│   │   ├── time_sync/
│   │   └── cloud_transport/
│   ├── processing/            # 处理层
│   │   ├── __init__.py
│   │   ├── privacy/
│   │   ├── quality/
│   │   └── labeling/
│   ├── storage/               # 存储层
│   │   ├── __init__.py
│   │   ├── edge_cache/
│   │   ├── cloud_storage/
│   │   └── format_converter/
│   ├── management/            # 管理层
│   │   ├── __init__.py
│   │   ├── task_manager/
│   │   ├── device_monitor/
│   │   └── access_control/
│   └── common/                # 公共模块
│       ├── __init__.py
│       ├── config.py
│       ├── logging.py
│       └── utils.py
├── tests/
│   ├── unit/
│   ├── integration/
│   └── performance/
├── docs/
└── scripts/
```

### 9.2 模块依赖关系

```
采集层          传输层          处理层          存储层          管理层
   │               │               │               │               │
   └───────────────┼───────────────┼───────────────┼───────────────┘
                   │               │               │
                   ↓               ↓               ↓
              ┌─────────────────────────────────────────┐
              │              common 公共模块              │
              │  (config, logging, utils, schemas)      │
              └─────────────────────────────────────────┘
```

---

## 第十章：技术选型与开发规范

### 10.1 技术栈选型

| 类别 | 技术 | 版本 | 用途 |
|------|------|------|------|
| **操作系统** | Ubuntu | 22.04 | 边缘端+云端 |
| **机器人框架** | ROS 2 Humble | LTS | 通信与控制 |
| **后端框架** | FastAPI | ≥0.100 | REST API |
| **前端框架** | React | ≥18 | 管理界面 |
| **AI推理** | TensorRT | 8.x | 边缘推理加速 |
| **数据库** | PostgreSQL | 15 | 元数据存储 |
| **向量库** | Milvus | 2.x | 语义检索 |
| **消息队列** | Redis | 7.x | 任务队列 |
| **对象存储** | MinIO/OSS | - | 数据存储 |
| **监控** | Prometheus+Grafana | - | 系统监控 |

### 10.2 开发语言

| 语言 | 使用场景 | 版本 |
|------|---------|------|
| Python | 主要开发语言，数据处理、AI推理 | ≥3.10 |
| C++ | 性能敏感模块，传感器驱动 | C++17 |
| TypeScript | Web管理界面 | ≥5.0 |

### 10.3 编码规范

**Python规范**:
- 遵循 PEP 8 风格指南
- 使用 Black 格式化工具
- 使用 mypy 进行类型检查
- 函数/类必须有 docstring

**命名约定**:

| 类型 | 规范 | 示例 |
|------|------|------|
| 模块名 | snake_case | `sensor_driver` |
| 类名 | PascalCase | `CameraDriver` |
| 函数名 | snake_case | `read_sensor_data()` |
| 常量 | UPPER_SNAKE | `MAX_BUFFER_SIZE` |
| ROS Topic | /namespace/module/type | `/camera/head_left/rgb` |

### 10.4 Git规范

**分支策略**:
- `main`: 主分支，稳定版本
- `develop`: 开发分支
- `feature/<name>`: 功能分支
- `bugfix/<name>`: 修复分支

**提交信息格式**:
```
<type>(<scope>): <subject>

feat(camera): add depth filtering support
fix(privacy): resolve face detection latency issue
docs(api): update REST API documentation
```

### 10.5 测试要求

| 测试类型 | 覆盖率要求 | 工具 |
|---------|-----------|------|
| 单元测试 | ≥80% | pytest |
| 集成测试 | 核心流程 | pytest + launch_testing |
| 性能测试 | 关键指标 | locust |

---

## 附录

### A. 快速启动命令

```bash
# 1. 环境准备
source /opt/ros/humble/setup.bash
source install/setup.bash

# 2. 启动边缘端系统
ros2 launch data_collection edge_system.launch.py

# 3. 启动遥操作模式
ros2 launch data_collection teleop_mode.launch.py

# 4. 启动管理界面
cd src/management/web && npm run dev
```

### B. 配置文件示例

```yaml
# config/system.yaml
system:
  node_name: "data_collection"
  log_level: "INFO"
  
edge:
  compute_device: "jetson_orin"
  storage_path: "/data/cache"
  cache_size_gb: 2000
  
cloud:
  enabled: true
  endpoint: "https://oss-cn-hangzhou.aliyuncs.com"
  bucket: "robot-data-collection"
  upload_strategy: "adaptive"
  
privacy:
  face_blur_enabled: true
  voice_anonymize_enabled: true
  sensitive_keywords: ["身份证", "银行卡", "密码"]
  
quality:
  sync_threshold_ms: 10
  image_sharpness_threshold: 100
  auto_grade_enabled: true
```

### C. 关键性能指标

| 指标 | 目标值 | 说明 |
|------|--------|------|
| 端到端延迟 | <50ms | 采集到缓存 |
| 同步精度 | ≤10ms | 多模态对齐 |
| 隐私脱敏延迟 | <40ms | 实时处理 |
| 数据完整率 | ≥99.5% | 无丢帧 |
| A级数据占比 | >60% | 质量目标 |

---

**文档信息**

| 项目 | 内容 |
|------|------|
| 版本 | V1.0 |
| 日期 | 2026年1月7日 |
| 状态 | 正式发布 |

---

**文档结束**

